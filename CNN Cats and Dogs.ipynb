{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Setting up the env'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Python program to create \n",
    "# Image Classifier using CNN \n",
    "\n",
    "# Importing the required libraries \n",
    "import cv2 \n",
    "import os \n",
    "import numpy as np \n",
    "from random import shuffle \n",
    "from tqdm import tqdm \n",
    "\n",
    "'''Setting up the env'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TRAIN_DIR = 'train'\n",
    "TEST_DIR = 'test1'\n",
    "IMG_SIZE = 50\n",
    "LR = 1e-3\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Setting up the model which will help with tensorflow models'''\n",
    "MODEL_NAME = 'dogsvscats-{}-{}.model'.format(LR, '6conv-basic') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Labelling the dataset'''\n",
    "def label_img(img): \n",
    "\tword_label = img.split('.')[-3] \n",
    "\t# DIY One hot encoder \n",
    "\tif word_label == 'cat': return [1, 0] \n",
    "\telif word_label == 'dog': return [0, 1] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Creating the training data'''\n",
    "def create_train_data(): \n",
    "\t# Creating an empty list where we should the store the training data \n",
    "\t# after a little preprocessing of the data \n",
    "\ttraining_data = [] \n",
    "\n",
    "\t# tqdm is only used for interactive loading \n",
    "\t# loading the training data \n",
    "\tfor img in tqdm(os.listdir(TRAIN_DIR)): \n",
    "\n",
    "\t\t# labeling the images \n",
    "\t\tlabel = label_img(img) \n",
    "\n",
    "\t\tpath = os.path.join(TRAIN_DIR, img) \n",
    "\n",
    "\t\t# loading the image from the path and then converting them into \n",
    "\t\t# greyscale for easier covnet prob \n",
    "\t\timg = cv2.imread(path, cv2.IMREAD_GRAYSCALE) \n",
    "\n",
    "\t\t# resizing the image for processing them in the covnet \n",
    "\t\timg = cv2.resize(img, (IMG_SIZE, IMG_SIZE)) \n",
    "\n",
    "\t\t# final step-forming the training data list with numpy array of the images \n",
    "\t\ttraining_data.append([np.array(img), np.array(label)]) \n",
    "\n",
    "\t# shuffling of the training data to preserve the random state of our data \n",
    "\tshuffle(training_data) \n",
    "\n",
    "\t# saving our trained data for further uses if required \n",
    "\tnp.save('train_data.npy', training_data) \n",
    "\treturn training_data \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Processing the given test data'''\n",
    "# Almost same as processing the traning data but \n",
    "# we dont have to label it. \n",
    "def process_test_data(): \n",
    "\ttesting_data = [] \n",
    "\tfor img in tqdm(os.listdir(TEST_DIR)): \n",
    "\t\tpath = os.path.join(TEST_DIR, img) \n",
    "\t\timg_num = img.split('.')[0] \n",
    "\t\timg = cv2.imread(path, cv2.IMREAD_GRAYSCALE) \n",
    "\t\timg = cv2.resize(img, (IMG_SIZE, IMG_SIZE)) \n",
    "\t\ttesting_data.append([np.array(img), img_num]) \n",
    "\t\t\n",
    "\tshuffle(testing_data) \n",
    "\tnp.save('test_data.npy', testing_data) \n",
    "\treturn testing_data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [03:45<00:00, 110.98it/s]\n",
      "100%|██████████| 12500/12500 [01:17<00:00, 162.26it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''Running the training and the testing in the dataset for our model'''\n",
    "train_data = create_train_data() \n",
    "test_data = process_test_data() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0717 20:10:03.573524 140632683738944 deprecation_wrapper.py:119] From /home/rohitbhalerao/anaconda3/lib/python3.7/site-packages/tflearn/helpers/summarizer.py:9: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
      "\n",
      "W0717 20:10:03.587445 140632683738944 deprecation_wrapper.py:119] From /home/rohitbhalerao/anaconda3/lib/python3.7/site-packages/tflearn/helpers/trainer.py:25: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "W0717 20:10:03.838390 140632683738944 deprecation_wrapper.py:119] From /home/rohitbhalerao/anaconda3/lib/python3.7/site-packages/tflearn/collections.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "W0717 20:10:03.976870 140632683738944 deprecation_wrapper.py:119] From /home/rohitbhalerao/anaconda3/lib/python3.7/site-packages/tflearn/config.py:123: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "W0717 20:10:04.042634 140632683738944 deprecation_wrapper.py:119] From /home/rohitbhalerao/anaconda3/lib/python3.7/site-packages/tflearn/config.py:129: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "W0717 20:10:04.058229 140632683738944 deprecation_wrapper.py:119] From /home/rohitbhalerao/anaconda3/lib/python3.7/site-packages/tflearn/config.py:131: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train_data = np.load('train_data.npy') \n",
    "# test_data = np.load('test_data.npy') \n",
    "'''Creating the neural network using tensorflow'''\n",
    "# Importing the required libraries \n",
    "import tflearn \n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d \n",
    "from tflearn.layers.core import input_data, dropout, fully_connected \n",
    "from tflearn.layers.estimator import regression \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "tf.reset_default_graph() \n",
    "convnet = input_data(shape =[None, IMG_SIZE, IMG_SIZE, 1], name ='input') \n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation ='relu') \n",
    "convnet = max_pool_2d(convnet, 5) \n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation ='relu') \n",
    "convnet = max_pool_2d(convnet, 5) \n",
    "\n",
    "convnet = conv_2d(convnet, 128, 5, activation ='relu') \n",
    "convnet = max_pool_2d(convnet, 5) \n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation ='relu') \n",
    "convnet = max_pool_2d(convnet, 5) \n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation ='relu') \n",
    "convnet = max_pool_2d(convnet, 5) \n",
    "\n",
    "convnet = fully_connected(convnet, 1024, activation ='relu') \n",
    "convnet = dropout(convnet, 0.8) \n",
    "\n",
    "convnet = fully_connected(convnet, 2, activation ='softmax') \n",
    "convnet = regression(convnet, optimizer ='adam', learning_rate = LR, \n",
    "\tloss ='categorical_crossentropy', name ='targets') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tflearn.DNN(convnet, tensorboard_dir ='log') \n",
    "\n",
    "# Splitting the testing data and training data \n",
    "train = train_data[:-500] \n",
    "test = train_data[-500:] \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Setting up the features and lables'''\n",
    "# X-Features & Y-Labels \n",
    "\n",
    "X = np.array([i[0] for i in train]).reshape(-1, IMG_SIZE, IMG_SIZE, 1) \n",
    "Y = [i[1] for i in train] \n",
    "test_x = np.array([i[0] for i in test]).reshape(-1, IMG_SIZE, IMG_SIZE, 1) \n",
    "test_y = [i[1] for i in test] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1914  | total loss: \u001b[1m\u001b[32m0.38004\u001b[0m\u001b[0m | time: 58.036s\n",
      "| Adam | epoch: 005 | loss: 0.38004 - acc: 0.8252 -- iter: 24448/24500\n",
      "Training Step: 1915  | total loss: \u001b[1m\u001b[32m0.37686\u001b[0m\u001b[0m | time: 59.197s\n",
      "| Adam | epoch: 005 | loss: 0.37686 - acc: 0.8255 | val_loss: 0.48599 - val_acc: 0.7720 -- iter: 24500/24500\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "'''Fitting the data into our model'''\n",
    "# epoch = 5 taken \n",
    "model.fit({'input': X}, {'targets': Y}, n_epoch = 5, \n",
    "\tvalidation_set =({'input': test_x}, {'targets': test_y}), \n",
    "\tsnapshot_step = 500, show_metric = True, run_id = MODEL_NAME) \n",
    "model.save(MODEL_NAME) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''Testing the data'''\n",
    "import matplotlib.pyplot as plt \n",
    "# if you need to create the data: \n",
    "# test_data = process_test_data() \n",
    "# if you already have some saved: \n",
    "np_load_old = np.load\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "test_data = np.load('test_data.npy') \n",
    "\n",
    "fig = plt.figure() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for num, data in enumerate(test_data[:20]): \n",
    "\t# cat: [1, 0] \n",
    "\t# dog: [0, 1] \n",
    "\t\n",
    "\timg_num = data[1] \n",
    "\timg_data = data[0] \n",
    "\t\n",
    "\ty = fig.add_subplot(4, 5, num + 1) \n",
    "\torig = img_data \n",
    "\tdata = img_data.reshape(IMG_SIZE, IMG_SIZE, 1) \n",
    "\n",
    "\t# model_out = model.predict([data])[0] \n",
    "\tmodel_out = model.predict([data])[0] \n",
    "\t\n",
    "\tif np.argmax(model_out) == 1: str_label ='Dog'\n",
    "\telse: str_label ='Cat'\n",
    "\t\t\n",
    "\ty.imshow(orig, cmap ='gray') \n",
    "\tplt.title(str_label) \n",
    "\ty.axes.get_xaxis().set_visible(False) \n",
    "\ty.axes.get_yaxis().set_visible(False) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0717 21:20:09.903237 140632683738944 deprecation.py:323] From /home/rohitbhalerao/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded!\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('{}.meta'.format(MODEL_NAME)):\n",
    "    model.load(MODEL_NAME)\n",
    "    print('model loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
