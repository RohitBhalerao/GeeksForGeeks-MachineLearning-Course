{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torchvision.datasets as dsets \n",
    "import torchvision.transforms as transforms \n",
    "from torch.autograd import Variable \n",
    "\n",
    "\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST Dataset (Images and Labels) \n",
    "train_dataset = dsets.MNIST(root ='./data', \n",
    "\t\t\t\t\t\t\ttrain = True, \n",
    "\t\t\t\t\t\t\ttransform = transforms.ToTensor(), \n",
    "\t\t\t\t\t\t\tdownload = True) \n",
    "\n",
    "test_dataset = dsets.MNIST(root ='./data', \n",
    "\t\t\t\t\t\ttrain = False, \n",
    "\t\t\t\t\t\ttransform = transforms.ToTensor()) \n",
    "\n",
    "# Dataset Loader (Input Pipline) \n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, \n",
    "\t\t\t\t\t\t\t\t\t\tbatch_size = batch_size, \n",
    "\t\t\t\t\t\t\t\t\t\tshuffle = True) \n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset, \n",
    "\t\t\t\t\t\t\t\t\t\tbatch_size = batch_size, \n",
    "\t\t\t\t\t\t\t\t\t\tshuffle = False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hyper Parameters \n",
    "input_size = 784\n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model \n",
    "class LogisticRegression(nn.Module): \n",
    "\tdef __init__(self, input_size, num_classes): \n",
    "\t\tsuper(LogisticRegression, self).__init__() \n",
    "\t\tself.linear = nn.Linear(input_size, num_classes) \n",
    "\n",
    "\tdef forward(self, x): \n",
    "\t\tout = self.linear(x) \n",
    "\t\treturn out \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = LogisticRegression(input_size, num_classes) \n",
    "\n",
    "# Loss and Optimizer \n",
    "# Softmax is internally computed. \n",
    "# Set parameters to be updated. \n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 1/ 5], Step: [ 100/ 600], Loss: 2.1266\n",
      "Epoch: [ 1/ 5], Step: [ 200/ 600], Loss: 2.0256\n",
      "Epoch: [ 1/ 5], Step: [ 300/ 600], Loss: 1.9791\n",
      "Epoch: [ 1/ 5], Step: [ 400/ 600], Loss: 1.8130\n",
      "Epoch: [ 1/ 5], Step: [ 500/ 600], Loss: 1.7787\n",
      "Epoch: [ 1/ 5], Step: [ 600/ 600], Loss: 1.7281\n",
      "Epoch: [ 2/ 5], Step: [ 100/ 600], Loss: 1.6349\n",
      "Epoch: [ 2/ 5], Step: [ 200/ 600], Loss: 1.6558\n",
      "Epoch: [ 2/ 5], Step: [ 300/ 600], Loss: 1.5216\n",
      "Epoch: [ 2/ 5], Step: [ 400/ 600], Loss: 1.4843\n",
      "Epoch: [ 2/ 5], Step: [ 500/ 600], Loss: 1.4582\n",
      "Epoch: [ 2/ 5], Step: [ 600/ 600], Loss: 1.3589\n",
      "Epoch: [ 3/ 5], Step: [ 100/ 600], Loss: 1.4638\n",
      "Epoch: [ 3/ 5], Step: [ 200/ 600], Loss: 1.3887\n",
      "Epoch: [ 3/ 5], Step: [ 300/ 600], Loss: 1.3033\n",
      "Epoch: [ 3/ 5], Step: [ 400/ 600], Loss: 1.2986\n",
      "Epoch: [ 3/ 5], Step: [ 500/ 600], Loss: 1.2405\n",
      "Epoch: [ 3/ 5], Step: [ 600/ 600], Loss: 1.2181\n",
      "Epoch: [ 4/ 5], Step: [ 100/ 600], Loss: 1.2667\n",
      "Epoch: [ 4/ 5], Step: [ 200/ 600], Loss: 1.1763\n",
      "Epoch: [ 4/ 5], Step: [ 300/ 600], Loss: 1.0655\n",
      "Epoch: [ 4/ 5], Step: [ 400/ 600], Loss: 1.0494\n",
      "Epoch: [ 4/ 5], Step: [ 500/ 600], Loss: 1.0789\n",
      "Epoch: [ 4/ 5], Step: [ 600/ 600], Loss: 1.0555\n",
      "Epoch: [ 5/ 5], Step: [ 100/ 600], Loss: 1.1006\n",
      "Epoch: [ 5/ 5], Step: [ 200/ 600], Loss: 1.0485\n",
      "Epoch: [ 5/ 5], Step: [ 300/ 600], Loss: 0.9731\n",
      "Epoch: [ 5/ 5], Step: [ 400/ 600], Loss: 1.1437\n",
      "Epoch: [ 5/ 5], Step: [ 500/ 600], Loss: 1.0287\n",
      "Epoch: [ 5/ 5], Step: [ 600/ 600], Loss: 1.0096\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training the Model \n",
    "for epoch in range(num_epochs): \n",
    "\tfor i, (images, labels) in enumerate(train_loader): \n",
    "\t\timages = Variable(images.view(-1, 28 * 28)) \n",
    "\t\tlabels = Variable(labels) \n",
    "\n",
    "\t\t# Forward + Backward + Optimize \n",
    "\t\toptimizer.zero_grad() \n",
    "\t\toutputs = model(images) \n",
    "\t\tloss = criterion(outputs, labels) \n",
    "\t\tloss.backward() \n",
    "\t\toptimizer.step() \n",
    "\n",
    "\t\tif (i + 1) % 100 == 0: \n",
    "\t\t\tprint('Epoch: [% d/% d], Step: [% d/% d], Loss: %.4f'\n",
    "\t\t\t\t% (epoch + 1, num_epochs, i + 1, len(train_dataset) // batch_size, loss.item())) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
